{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Automated ML\r\n",
    "\r\n",
    "Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import logging\r\n",
    "import csv\r\n",
    "\r\n",
    "import azureml.core\r\n",
    "from azureml.core import Workspace\r\n",
    "from azureml.core import Experiment\r\n",
    "from azureml.core import Environment\r\n",
    "from azureml.core import ScriptRunConfig\r\n",
    "\r\n",
    "from azureml.core import Datastore\r\n",
    "from azureml.core.dataset import Dataset\r\n",
    "\r\n",
    "from azureml.train.automl import AutoMLConfig\r\n",
    "\r\n",
    "from azureml.widgets import RunDetails"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.33.0\n"
     ]
    }
   ],
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(azureml.core.VERSION)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "create an instance of Workspace and get an an Experiment instance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "ws = Workspace.from_config()\r\n",
    "\r\n",
    "# choose a name for experiment\r\n",
    "experiment_name = 'udacity-capstone-project'\r\n",
    "project_folder = \"automl-heartfailure\"\r\n",
    "experiments = Experiment.list(ws, experiment_name=experiment_name)\r\n",
    "\r\n",
    "if not experiments:\r\n",
    "    experiment = Experiment(workspace=ws, name=experiment_name)\r\n",
    "else:\r\n",
    "    experiment = experiments[0]\r\n",
    "\r\n",
    "print('Workspace name: ' + ws.name, \r\n",
    "    'Azure region: ' + ws.location, \r\n",
    "    'Subscription id: ' + ws.subscription_id, \r\n",
    "    'Resource group: ' + ws.resource_group, sep = '\\n')\r\n",
    "\r\n",
    "run = experiment.start_logging()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32m<ipython-input-3-0b8cd612e388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      3\u001b[0m \u001b[1;31m# choose a name for experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[0mexperiment_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'your experiment name here'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\core\\workspace.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(path, auth, _logger, _file_name)\u001b[0m\n",
      "\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    292\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found the config file in: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfound_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 293\u001b[1;33m         return Workspace.get(\n",
      "\u001b[0m\u001b[0;32m    294\u001b[0m             \u001b[0mworkspace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    295\u001b[0m             \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\core\\workspace.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(name, auth, subscription_id, resource_group, location, cloud, id)\u001b[0m\n",
      "\u001b[0;32m    597\u001b[0m         \"\"\"\n",
      "\u001b[0;32m    598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 599\u001b[1;33m             \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInteractiveLoginAuthentication\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    601\u001b[0m         return Workspace(\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\core\\authentication.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, force, tenant_id, cloud)\u001b[0m\n",
      "\u001b[0;32m    523\u001b[0m                     print(\"Performing interactive authentication. Please follow the instructions \"\n",
      "\u001b[0;32m    524\u001b[0m                           \"on the terminal.\")\n",
      "\u001b[1;32m--> 525\u001b[1;33m                     \u001b[0mperform_interactive_login\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtenant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtenant_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloud_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cloud_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    526\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interactive authentication successfully completed.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\_base_sdk_common\\common.py\u001b[0m in \u001b[0;36mperform_interactive_login\u001b[1;34m(username, password, service_principal, tenant, allow_no_subscriptions, identity, use_device_code, use_cert_sn_issuer, cloud_type)\u001b[0m\n",
      "\u001b[0;32m    569\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0madal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madal_error\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdalError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 571\u001b[1;33m         subscriptions = profile.find_subscriptions_on_login(\n",
      "\u001b[0m\u001b[0;32m    572\u001b[0m             \u001b[0minteractive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    573\u001b[0m             \u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\_vendor\\azure_cli_core\\_profile.py\u001b[0m in \u001b[0;36mfind_subscriptions_on_login\u001b[1;34m(self, interactive, username, password, is_service_principal, tenant, use_device_code, allow_no_subscriptions, subscription_finder, use_cert_sn_issuer)\u001b[0m\n",
      "\u001b[0;32m    218\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    219\u001b[0m                     \u001b[0mauthority_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_authority_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtenant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 220\u001b[1;33m                     subscriptions = subscription_finder.find_through_authorization_code_flow(\n",
      "\u001b[0m\u001b[0;32m    221\u001b[0m                         tenant, self._ad_resource_uri, authority_url)\n",
      "\u001b[0;32m    222\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\_vendor\\azure_cli_core\\_profile.py\u001b[0m in \u001b[0;36mfind_through_authorization_code_flow\u001b[1;34m(self, tenant, resource, authority_url)\u001b[0m\n",
      "\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    775\u001b[0m         \u001b[1;31m# launch browser and get the code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 776\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_authorization_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthority_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\azure\\lib\\site-packages\\azureml\\_vendor\\azure_cli_core\\_profile.py\u001b[0m in \u001b[0;36m_get_authorization_code\u001b[1;34m(resource, authority_url)\u001b[0m\n",
      "\u001b[0;32m   1130\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1131\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 1132\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# so that ctrl+c can stop the command\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1134\u001b[0m             \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\r\n",
    "\r\n",
    "### Overview\r\n",
    "Cardiovascular diseases (CVDs) are the number 1 cause of death globally. \r\n",
    "CVDs commonly causes heart failures. \r\n",
    "Early detection of heart failure is one way of addressing the problem. \r\n",
    "Here we use machine learning approach to build a classification model relying on a Heart Failure prediction dataset. \r\n",
    "This dataset is available in Kaggle. \r\n",
    "The dataset consists of 12 features that are cardiovascular disease, hypertension, diabetes and so on.\r\n",
    "\r\n",
    "TODO: Also mention the task you will be performing.\r\n",
    "\r\n",
    "The goal is to build a binary classification model that predict heart failure.\r\n",
    "\r\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from train import clean_data\r\n",
    "\r\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
    "\r\n",
    "# Create a Dataset instance\r\n",
    "found = False\r\n",
    "key = \"HeartFailurePrediction\"\r\n",
    "description_text = \"Heart Failure Prediction DataSet for Udacity Capstone Project\"\r\n",
    "\r\n",
    "if key in ws.datasets.keys(): \r\n",
    "    found = True\r\n",
    "    dataset_tmp = ws.datasets[key] \r\n",
    "else:\r\n",
    "    print(\"Register heart_failure_clinical_records_dataset.csv into Workspace\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get defaut_datastore\r\n",
    "datastore = ws.get_default_datastore()\r\n",
    "\r\n",
    "try:\r\n",
    "    ds_prepared = TabularDatasetFactory.from_delimited_files(datastore.path(\"data/heartfailure_prepared.csv\"))\r\n",
    "except:\r\n",
    "    print(\"heartfailure_prepared.csv is not available\")\r\n",
    "    ds_prepared = None\r\n",
    "\r\n",
    "if not ds_prepared:\r\n",
    "    # Use the clean_data function to clean your data.\r\n",
    "    x, y = clean_data(dataset_tmp) \r\n",
    "\r\n",
    "    x[\"DEATH_EVENT\"] = y\r\n",
    "\r\n",
    "    os.makedirs(os.path.join(\".\", \"data\"), exist_ok=True)\r\n",
    "    x.to_csv(os.path.join(\".\", \"data\", \"heartfailure_prepared.csv\"), index=False)\r\n",
    "\r\n",
    "    datastore.upload(os.path.join(\".\", \"data\"), target_path=\"data\")\r\n",
    "\r\n",
    "    ds_prepared = TabularDatasetFactory.from_delimited_files(datastore.path(\"data/heartfailure_prepared.csv\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create compute targets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.core.compute_target import ComputeTargetException\r\n",
    "\r\n",
    "# Create compute cluster\r\n",
    "cpu_cluster_name = \"cpu-cluster-01vx\"\r\n",
    "vm_size = \"Standard_DS3_v2\"\r\n",
    "min_nodes = 0\r\n",
    "max_nodes = 6\r\n",
    "\r\n",
    "\r\n",
    "try:\r\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\r\n",
    "    print(\"Found existing cluster. use it\")\r\n",
    "except ComputeTargetException:\r\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\r\n",
    "                                                           min_nodes=min_nodes,\r\n",
    "                                                           max_nodes=max_nodes)\r\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\r\n",
    "\r\n",
    "compute_target.wait_for_completion(show_output=True)\r\n",
    "\r\n",
    "# a detailed status for the current cluster.\r\n",
    "print(compute_target.get_status().serialize())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AutoML Configuration\r\n",
    "\r\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below.\r\n",
    "\r\n",
    "Our task is to build a binary classification model. \r\n",
    "The model's performance was measured with the accuracy.\r\n",
    "To reduce the overfitting of the model, cross validations was used. \r\n",
    "To save the model, enable_onnx_compatible_models was set to be True."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Put your automl settings here\r\n",
    "automl_settings = {\r\n",
    "    \"experiment_timeout_minutes\": 30,\r\n",
    "    \"max_concurrent_iterations\": max_nodes-1,\r\n",
    "    \"primary_metric\" : 'accuracy',\r\n",
    "    \"n_cross_validations\" : 5,\r\n",
    "    \"enable_onnx_compatible_models\" : True\r\n",
    "}\r\n",
    "\r\n",
    "# TODO: Put your automl config here\r\n",
    "\r\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\r\n",
    "                             task = \"classification\",\r\n",
    "                             training_data=ds_prepared,\r\n",
    "                             label_column_name=\"DEATH_EVENT\",\r\n",
    "                             path = project_folder,\r\n",
    "                             enable_early_stopping= True,\r\n",
    "                             featurization= 'auto',\r\n",
    "                             debug_log = \"automl_errors.log\",\r\n",
    "                             **automl_settings\r\n",
    "                            )"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Submit your experiment\r\n",
    "automl_run = experiment.submit(automl_config)"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Details\r\n",
    "\r\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\r\n",
    "\r\n",
    "In the cell below, use the `RunDetails` widget to show the different experiments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "RunDetails(automl_run).show()"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "automl_run.wait_for_completion(show_output=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_run, best_model = automl_run.get_output(return_onnx_model=True)\r\n",
    "\r\n",
    "best_model  #best_model.steps"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#TODO: Save the best model\r\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\r\n",
    "\r\n",
    "OnnxConverter.save_onnx_model(best_model, file_path=\"./automl_model.onnx\")"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Register the model to deploy\r\n",
    "model = automl_run.register_model(\r\n",
    "    model_name=key, \r\n",
    "    description=\"Binary classification model for Heart Failure prediction\" \r\n",
    ")\r\n",
    "\r\n",
    "print(model.id)"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Local Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "local_env = best_run.get_environment()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core.model import InferenceConfig, Model\r\n",
    "from azureml.core.webservice import LocalWebservice\r\n",
    "\r\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\r\n",
    "\r\n",
    "dummy_inference_config = InferenceConfig(\r\n",
    "    environment=local_env,\r\n",
    "    source_directory=\"./source_dir\",\r\n",
    "    entry_script=\"./score.py\",\r\n",
    ")\r\n",
    "\r\n",
    "local_service = Model.deploy(\r\n",
    "    workspace = ws,\r\n",
    "    name = key.lower(),\r\n",
    "    models = [model],\r\n",
    "    inference_config = dummy_inference_config,\r\n",
    "    deployment_config = deployment_config,\r\n",
    "    overwrite=True,\r\n",
    ")\r\n",
    "\r\n",
    "local_service.wait_for_deployment(show_output=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import json\r\n",
    "\r\n",
    "local_uri = local_service.scoring_uri\r\n",
    "requests.get(\"http://localhost:6789\")\r\n",
    "headers = {\"Content-Type\": \"application/json\"}\r\n",
    "data = {\"data\":\r\n",
    "        [\r\n",
    "            {\r\n",
    "                \"age\" : \"65\", \r\n",
    "                \"anaemia\" : \"0\",\r\n",
    "                \"creatinine_phosphokinase\" : \"146\",\r\n",
    "                \"diabetes\" : \"0\", \r\n",
    "                \"ejection_fraction\" : \"20\",\r\n",
    "                \"high_blood_pressure\" : \"0\",\r\n",
    "                \"platelets\" : \"162000\",\r\n",
    "                \"serum_creatinine\" : \"1.3\", \r\n",
    "                \"serum_sodium\" : \"129\",\r\n",
    "                \"sex\" : \"1\",\r\n",
    "                \"smoking\" : \"1\",\r\n",
    "                \"time\" : \"7\"\r\n",
    "            },\r\n",
    "        ]\r\n",
    "        }\r\n",
    "\r\n",
    "input_data = json.dumps(data)\r\n",
    "response = requests.post(local_uri, data=input_data, headers=headers)\r\n",
    "print(response.json())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deployed environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile conda_dependencies.yml\r\n",
    "\r\n",
    "dependencies:\r\n",
    "- python=3.6.2\r\n",
    "- numpy\r\n",
    "- pandas\r\n",
    "- scikit-learn\r\n",
    "- onnxruntime\r\n",
    "- pip:\r\n",
    "  - azureml-defaults"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# env = Environment(name=\"project_environment\")\r\n",
    "sklearn_env = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core.model import InferenceConfig, Model\r\n",
    "from azureml.core.webservice import AciWebservice, Webservice\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Combine scoring script & environment in Inference configuration\r\n",
    "inference_config = InferenceConfig( environment=_sklearn_env, source_directory='./source_dir', entry_script='./score.py')\r\n",
    "\r\n",
    "# Set deployment configuration\r\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, auth_enabled = True, enable_app_insights=True)\r\n",
    "\r\n",
    "# Define the model, inference, & deployment configuration and web service name and location to deploy\r\n",
    "service = Model.deploy(\r\n",
    "    workspace = ws,\r\n",
    "    name = key,\r\n",
    "    models = [model],\r\n",
    "    inference_config = inference_config,\r\n",
    "    deployment_config = deployment_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "deployment_config.get_keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
    "\r\n",
    "interactive_auth = InteractiveLoginAuthentication()\r\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ],
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "\r\n",
    "uri = service.scoring_uri\r\n",
    "\r\n",
    "headers = {\"Content-Type\": \"application/json\"}\r\n",
    "# If authentication is enabled, set the authorization header\r\n",
    "headers['Authorization'] = f'Bearer {key}'\r\n",
    "\r\n",
    "data = {\r\n",
    "    \"age\" : \"65\", \r\n",
    "    \"anaemia\" : \"0\",\r\n",
    "    \"creatinine_phosphokinase\" : \"146\",\r\n",
    "    \"diabetes\" : \"0\", \r\n",
    "    \"ejection_fraction\" : \"20\",\r\n",
    "    \"high_blood_pressure\" : \"0\",\r\n",
    "    \"platelets\" : \"162000\",\r\n",
    "    \"serum_creatinine\" : \"1.3\", \r\n",
    "    \"serum_sodium\" : \"129\",\r\n",
    "    \"sex\" : \"1\",\r\n",
    "    \"smoking\" : \"1\",\r\n",
    "    \"time\" : \"7\",\r\n",
    "}\r\n",
    "input_data = json.dumps(data)\r\n",
    "response = requests.post(uri, data=input_data, headers=headers)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(response.json())"
   ],
   "outputs": [],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ],
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "service.get_logs()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "service.delete()\r\n",
    "model.delete()\r\n",
    "\r\n",
    "# compute_target.delete()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('azure': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "interpreter": {
   "hash": "b19a256a7d3812a8e0a3a61d7add31005087a7b63979c46bc7a1e05f0b16a33e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}